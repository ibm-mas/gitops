---
kind: Secret
apiVersion: v1
metadata:
  name: "aws-{{ .Values.db2_instance_name }}"
  namespace: "{{ .Values.db2_namespace }}"
data:
  aws_access_key_id: {{ .Values.sm.aws_access_key_id | b64enc }}
  aws_secret_access_key: {{ .Values.sm.aws_secret_access_key | b64enc }}
type: Opaque

---
# Service account that is authorized to read k8s secrets (needed by the job)
# TODO: Currently bound with cluster-admin; probably want to lock this down more
kind: ServiceAccount
apiVersion: v1
metadata:
  name: "postsync-sa-{{ .Values.db2_instance_name }}"
  namespace: "{{ .Values.db2_namespace }}"

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: "db2-database-postsync-sa-rb-{{ .Values.db2_instance_name }}"
subjects:
  - kind: ServiceAccount
    name: "postsync-sa-{{ .Values.db2_instance_name }}"
    namespace: "{{ .Values.db2_namespace }}"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin


---
apiVersion: batch/v1
kind: Job
metadata:
  name: "postsync-setup-db2-{{ .Values.db2_instance_name }}"
  namespace: "{{ .Values.db2_namespace }}"
  annotations:
    argocd.argoproj.io/hook: PostSync
    hook-delete-policy: before-hook-creation
spec:
  template:
    spec:
      containers:
        - name: run
          # TODO: use a dedicated image with a smaller footprint for this sort of thing?
          # Just using cli for now since it has all the deps we need to talk with AWS SM
          image: quay.io/ibmmas/cli:7.10.0-pre.mascore1425
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: 200m
              memory: 512Mi
            requests:
              cpu: 10m
              memory: 64Mi
          env:
            - name: ACCOUNT_ID
              value: {{ .Values.account.id }}
            - name: REGION_ID
              value: {{ .Values.region.id }}
            - name: CLUSTER_ID
              value: {{ .Values.cluster.id }}
            - name: MAS_INSTANCE_ID
              value: {{ .Values.instance.id }}
            - name: MAS_APP_ID
              value: {{ .Values.mas_application_id}}
            # Hard-coded for now:
            - name: AVP_TYPE
              value: "aws"
            - name: DB2_NAMESPACE
              value: "{{ .Values.db2_namespace }}"
            - name: DB2_INSTANCE_NAME
              value: "{{ .Values.db2_instance_name }}"
            - name: DB2_DBNAME
              value: "{{ .Values.db2_dbname }}"
          volumeMounts:
            - name: aws
              mountPath: /etc/mas/creds/aws
          command:
            - /bin/sh
            - -c
            - |

              set -e

              source /mascli/functions/gitops_utils
              export DB2CFG_SETTINGS_APPLIED_SECRET=${ACCOUNT_ID}/${CLUSTER_ID}/${MAS_INSTANCE_ID}/${MAS_APP_ID}/db2cfg

              echo ""
              echo "================================================================================"
              echo "Settings"
              echo "================================================================================"
              echo "ACCOUNT_ID .......................... ${ACCOUNT_ID}"
              echo "REGION_ID ........................... ${REGION_ID}"
              echo "CLUSTER_ID .......................... ${CLUSTER_ID}"
              echo "MAS_INSTANCE_ID ..................... ${MAS_INSTANCE_ID}"
              echo "MAS_APP_ID .......................... ${MAS_APP_ID}"
              echo "AVP_TYPE ............................ ${AVP_TYPE}"
              echo "DB2_NAMESPACE ....................... ${DB2_NAMESPACE}"
              echo "DB2_INSTANCE_NAME ................... ${DB2_INSTANCE_NAME}"
              echo "DB2_DBNAME .......................... ${DB2_DBNAME}"
              echo "DB2CFG_SETTINGS_APPLIED_SECRET ...... ${DB2CFG_SETTINGS_APPLIED_SECRET}"

              echo ""
              echo "================================================================================"
              echo "Checking ${DB2CFG_SETTINGS_APPLIED_SECRET}#db2cfg_settings_applied"
              echo "================================================================================"

              export SM_AWS_ACCESS_KEY_ID=$(cat /etc/mas/creds/aws/aws_access_key_id)
              export SM_AWS_SECRET_ACCESS_KEY=$(cat /etc/mas/creds/aws/aws_secret_access_key)
              export SM_AWS_REGION=${REGION_ID}
              sm_login
             
              export DB2CFG_SETTINGS_APPLIED=$(sm_get_secret_value ${DB2CFG_SETTINGS_APPLIED_SECRET} "db2cfg_settings_applied")
              # TODO: or we could skip rendering of this hook (and related templates) altogether if DB2CFG_SETTINGS_APPLIED is "true"?
              echo "DB2CFG_SETTINGS_APPLIED ............. ${DB2CFG_SETTINGS_APPLIED}"

              if [[ "${DB2CFG_SETTINGS_APPLIED}" == "true" ]]; then
                echo DB2 settings have been applied since the last change was made to the database configuration, exiting now "
                exit 0
              fi


              # TODO: what's the purpose of the DB2_INTERNAL flag (used in gitops_db2u_database).. 
              # surely any DB2 being spun up in this way via ArgoCD is considered "internal"?

              echo ""
              echo "================================================================================"
              echo "Calling apply-db2cfg-settings.sh file on c-${DB2_INSTANCE_NAME}-db2u-0"
              echo "================================================================================"
              oc exec -n ${DB2_NAMESPACE} c-${DB2_INSTANCE_NAME}-db2u-0 -- su -lc '/db2u/scripts/apply-db2cfg-settings.sh --setting all | tee /tmp/apply-db2cfg-settings.log' db2inst1
              rc=$?
              echo "oc exec apply-db2cfg-settings.sh rc: ${rc}"



              # Create backup script
              echo ""
              echo "================================================================================"
              echo "Invoke Suite DB2 Backup"
              echo "================================================================================"

              BACKUPDB_SH_PATH="/tmp/backupdb.sh"

              echo ""
              echo "Create ${BACKUPDB_SH_PATH}"
              echo "--------------------------------------------------------------------------------"

              # Check that connect returns SQL1116N which means BACKUP PENDING state
              if db2 connect to '${DB2_DBNAME}' | grep SQL1116N >/dev/null
              then

                  echo "backupdb.sh: Database connect returning SQL1116N, do backup now"

                  echo "backupdb.sh: Creating backup folder /mnt/backup"
                  mkdir -p /mnt/backup
                  rc=$?
                  [ $rc -ne 0 ] && exit $rc

                  echo "backupdb.sh: db2 force applications"
                  db2 force application all
                  rc=$?
                  [ $rc -ne 0 ] && exit $rc

                  echo "backupdb.sh: Turn off comms manager"
                  db2set -null DB2COMM
                  rc=$?
                  [ $rc -ne 0 ] && exit $rc

                  echo "backupdb.sh: Deactivate database"
                  db2 deactivate database '${DB2_DBNAME}'
                  rc=$?
                  [ $rc -ne 0 ] && exit $rc

                  echo "backupdb.sh: db2stop"
                  db2stop force
                  rc=$?
                  [ $rc -ne 0 ] && exit $rc

                  echo "backupdb.sh: db2start in admin mode"
                  db2start admin mode restricted access
                  rc=$?
                  [ $rc -ne 0 ] && exit $rc

                  # dbstart does not always start straight away, wait 20 seconds
                  sleep 20

                  echo "backupdb.sh: db2 backup db '${DB2_DBNAME}' on all dbpartitionnums"
                  db2 backup db '${DB2_DBNAME}' on all dbpartitionnums to /mnt/backup
                  rc=$?
                  [ $rc -ne 0 ] && exit $rc

                  echo "backupdb.sh: db2stop"
                  db2stop force
                  rc=$?
                  [ $rc -ne 0 ] && exit $rc

                  echo "backupdb.sh: db2set comms manager"
                  db2set DB2COMM=TCPIP,SSL
                  rc=$?
                  [ $rc -ne 0 ] && exit $rc

                  echo "backupdb.sh: db2start"
                  db2start
                  rc=$?
                  [ $rc -ne 0 ] && exit $rc

              else

                  echo "backupdb.sh: Database connect not returning SQL1116N, nothing to do"
                  exit 0

              fi
              ' > ${BACKUPDB_SH_PATH}


              echo ""
              echo "Copy ${BACKUPDB_SH_PATH} to ${DB2_NAMESPACE}/c-${DB2_INSTANCE_NAME}-db2u-0"
              echo "--------------------------------------------------------------------------------"
              oc exec -n ${DB2_NAMESPACE} c-${DB2_INSTANCE_NAME}-db2u-0 -- su -lc '/tmp/backupdb.sh | tee /tmp/backupdb.log' db2inst1

              echo ""
              echo "================================================================================"
              echo "Setting ${DB2CFG_SETTINGS_APPLIED_SECRET}#db2cfg_settings_applied to true"
              echo "================================================================================"
              export DB2CFG_SETTINGS_APPLIED="true"
              sm_update_secret ${DB2CFG_SETTINGS_APPLIED_SECRET} "{ \"db2cfg_settings_applied\": \"${DB2CFG_SETTINGS_APPLIED}\" }"
              rc=$?
              echo "sm_update_secret rc: ${rc}"


      restartPolicy: Never

      # TODO: is this the correct SA to use here?
      # No, probably want to add a more restricted SA that can just do things that these post-sync jobs need to do
      serviceAccountName: "postsync-sa-{{ .Values.db2_instance_name }}"
      volumes:
        - name: aws
          secret:
            secretName: "aws-{{ .Values.db2_instance_name }}"
            defaultMode: 420
            optional: false
  backoffLimit: 4