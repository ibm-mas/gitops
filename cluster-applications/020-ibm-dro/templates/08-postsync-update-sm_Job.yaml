{{- if .Values.run_sync_hooks }}

{{ $ns := .Values.dro_namespace}}
{{ $aws_secret := "aws"}}
{{ $role_name :=  "postsync-ibm-dro-update-sm-r" }}
{{ $sa_name :=    "postsync-ibm-dro-update-sm-sa" }}
{{ $rb_name :=    "postsync-ibm-dro-update-sm-rb" }}


---
kind: Secret
apiVersion: v1
metadata:
  name: {{ $aws_secret }}
  namespace: {{ $ns }}
  annotations:
    argocd.argoproj.io/sync-wave: "026"
{{- if .Values.custom_labels }}
  labels:
{{ .Values.custom_labels | toYaml | indent 4 }}
{{- end }}
data:
  aws_access_key_id: {{ .Values.sm_aws_access_key_id | b64enc }}
  aws_secret_access_key: {{ .Values.sm_aws_secret_access_key | b64enc }}
type: Opaque

---
kind: ServiceAccount
apiVersion: v1
metadata:
  name: {{ $sa_name }}
  namespace: {{ $ns }}
  annotations:
    argocd.argoproj.io/sync-wave: "026"
{{- if .Values.custom_labels }}
  labels:
{{ .Values.custom_labels | toYaml | indent 4 }}
{{- end }}

---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: {{ $role_name }}
  namespace: {{ $ns }}
  annotations:
    argocd.argoproj.io/sync-wave: "026"
{{- if .Values.custom_labels }}
  labels:
{{ .Values.custom_labels | toYaml | indent 4 }}
{{- end }}
rules:
  - verbs:
      - get
    apiGroups:
      - route.openshift.io
    resources:
      - routes


---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: {{ $rb_name }}
  namespace: {{ $ns }}
  annotations:
    argocd.argoproj.io/sync-wave: "027"
{{- if .Values.custom_labels }}
  labels:
{{ .Values.custom_labels | toYaml | indent 4 }}
{{- end }}
subjects:
  - kind: ServiceAccount
    name: {{ $sa_name }}
    namespace: {{ $ns }}
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: {{ $role_name }}

---
apiVersion: batch/v1
kind: Job
metadata:
  # Generate the job name by suffixing with a hash of all chart values
  # This is to ensure that ArgoCD will delete and recreate the job if (and only if) anything changes
  # Any change to cluster config will trigger a rerun of the job. 
  # We can refine this in future to only take into account a subset of instance config (perhaps just values under ibm_dro?).
  # But the job is idempotent and quick so no real harm in running it when we don't actually need to.
  name: "postsync-ibm-dro-update-sm-job-{{ .Values | toYaml | adler32sum }}"
  namespace: {{ $ns }}
  annotations:
    argocd.argoproj.io/sync-wave: "028"
{{- if .Values.custom_labels }}
  labels:
{{ .Values.custom_labels | toYaml | indent 4 }}
{{- end }}
spec:
  template:
{{- if .Values.custom_labels }}
    metadata:
      labels:
{{ .Values.custom_labels | toYaml | indent 8 }}
{{- end }}
    spec:
      containers:
        - name: run
          image: quay.io/ibmmas/cli:9.4.0-pre.gitops
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: 200m
              memory: 512Mi
            requests:
              cpu: 10m
              memory: 64Mi
          env:
            - name: ACCOUNT_ID
              value: {{ .Values.account_id }}
            - name: REGION_ID
              value: {{ .Values.region_id }}
            - name: CLUSTER_ID
              value: {{ .Values.cluster_id }}
            - name: DRO_NAMESPACE
              value: {{ .Values.dro_namespace }}
            # Hard-coded for now:
            - name: AVP_TYPE
              value: "aws"
          volumeMounts:
            - name: aws
              mountPath: /etc/mas/creds/aws
            - name: ibm-data-reporter-operator-api-token
              mountPath: /etc/mas/creds/ibm-data-reporter-operator-api-token
          command:
            - /bin/sh
            - -c
            - |

              set -e

              # might as well take advantage of gitops_utils for sm_ functions as we're using the cli image
              source /mascli/functions/gitops_utils

              function wait_for_resource {
                RES_TYPE="$1"
                RES_NAME="$2"
                RES_NS="$3"
                RETRIES=${4:-10}
                RETRY_DELAY_SECONDS=${5:-30}

                for (( c=1; c<="${RETRIES}"; c++ )); do

                  echo "... attempt ${c} of ${RETRIES}"

                  rc=0
                  oc get "${RES_TYPE}/${RES_NAME}" -n "${RES_NAMESPACE}" || rc=$?
                  if [[ "$rc" == "0" ]]; then
                    echo "...... success"
                    return 0
                  fi

                  if [[ "${c}" -lt "${RETRIES}" ]]; then
                    echo "...... failed (rc: ${rc}), retry in ${RETRY_DELAY_SECONDS}s"
                    sleep $RETRY_DELAY_SECONDS
                  fi
                done

                echo "...... failed, no attempts remain"
                return 1
              }


              echo ""
              echo "================================================================================"
              echo "Waiting for route ibm-data-reporter to be present before continuing (timeout 300s)"
              echo "================================================================================"
              wait_for_resource "route" "ibm-data-reporter" "${DRO_NAMESPACE}"


              # NOTE: cannot just render AWS secrets into here, as it will be exposed in the ArgoCD UI
              # Instead, we pass them into a secret (ArgoCD knows to hide any data fields in k8s secrets),
              # mount the secret on the jobs filesystem, and read them in here
              SM_AWS_ACCESS_KEY_ID=$(cat /etc/mas/creds/aws/aws_access_key_id)
              SM_AWS_SECRET_ACCESS_KEY=$(cat /etc/mas/creds/aws/aws_secret_access_key)

              export DRO_HOST="$(oc get route ibm-data-reporter -n ${DRO_NAMESPACE} -ojsonpath='{.spec.host}')"
              if [[ -z "${DRO_HOST}" ]]; then
                echo "Failed to fetch dro host from route"
                exit 1
              fi
              export DRO_URL="https://${DRO_HOST}"

              echo "Fetching token from ibm-data-reporter-operator-api-token Secret in ${DRO_NAMESPACE}"
              export DRO_API_TOKEN=$(cat /etc/mas/creds/ibm-data-reporter-operator-api-token/token)
              if [[ -z "${DRO_API_TOKEN}" ]]; then
                echo "Failed to fetch token"
                exit 1
              fi


              # aws configure set aws_access_key_id $SM_AWS_ACCESS_KEY_ID
              # aws configure set aws_secret_access_key $SM_AWS_SECRET_ACCESS_KEY
              # aws configure set default.region $REGION_ID
              # aws configure list
              export SM_AWS_REGION=${REGION_ID}
              sm_login

              # aws secretsmanager create-secret --name ${SECRET_NAME} --secret-string "${SECRET_VALUE}"
              SECRET_NAME_DRO=${ACCOUNT_ID}/${CLUSTER_ID}/dro
              sm_update_secret $SECRET_NAME_DRO "{\"dro_api_token\": \"$DRO_API_TOKEN\", \"dro_url\": \"$DRO_URL\" }"


      restartPolicy: Never

      # TODO: is this the correct SA to use here?
      # No, probably want to add a more restricted SA that can just do things that these post-sync jobs need to do
      serviceAccountName: {{ $sa_name }}
      volumes:
        - name: aws
          secret:
            secretName: {{ $aws_secret }}
            defaultMode: 420
            optional: false
        - name: ibm-data-reporter-operator-api-token
          secret:
            secretName: ibm-data-reporter-operator-api-token
            defaultMode: 420
            optional: false
  backoffLimit: 4
{{- end }}



